{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Society Term 2 Workshop 1 - Intro to Deep Learning (Problems)\n",
    "Now it is your turn build a neural network! Follow the instructions below and feel free to refer back to the workshop notebook throughout.\n",
    "## Importing\n",
    "We begin by importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = \"theano\"\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "Here we look at the fashion mnist dataset. The data is structured in a similar manner to the mnist dataset we looked at earlier. The key difference is that the images represent clothing items and the classifications will also be different as a result. There are ten values for $y$ each indicating a different type of clothing as indicated below.\n",
    "\n",
    "0 T-shirt/top\n",
    "\n",
    "1 Trouser\n",
    "\n",
    "2 Pullover\n",
    "\n",
    "3 Dress\n",
    "\n",
    "4 Coat\n",
    "\n",
    "5 Sandal\n",
    "\n",
    "6 Shirt\n",
    "\n",
    "7 Sneaker\n",
    "\n",
    "8 Bag\n",
    "\n",
    "9 Ankle boot\n",
    "\n",
    "The code cell below loads in the dataset for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the fashion mnist dataset\n",
    "fash_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "# Seperating into training and test sets\n",
    "(X_train, y_train), (X_test, y_test) = fash_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "Begin by plotting the first image from the ````X_train```` \"tensor\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "Using the ````Sequential```` model from ````keras```` construct a neural network whose input layer consists of flattened data. Use only one hidden layer with $16$ neurons and the rectified linear activation function. For the output layer use the softmax activation function. For training use the ````adam```` optimizer and ````sparse_categorical_crossentropy```` for loss. Ensure your model keeps track of the accuracy and that complete training occurs after three passes through the data. Once the architecture of your network is defined and the parameters for training are specified proceed by passing your training data into the model. One should note that there will naturally be other ways of building neural networks for this problem. You are only asked for these specific parameters to get a result thats closer to the solutions but you are more than welcome to try other means!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring \n",
    "Now return the accuracy of your model. You should find it to be rather low if you haven't already normalised the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise the Data\n",
    "Normalise the ````X_train```` and ````X_test```` data using ````axis=1```` and then pass the now normalised training data into the neural network again. You should find the accuracy has improved as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Now return the first prediction for your model based on the test data. See if the prediction matches the first ````y_test```` value.  For completeness you may also want to display the image of the sample tested. If the first sample doesn't produce the correct result you may want to check if subsequent samples can give the correct prediction as we will never truly have $100%$ accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the image of the sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
